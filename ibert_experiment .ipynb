{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"47lAsvQJmyBa","outputId":"9469fbec-62cd-4856-dfc0-7d3489021100","executionInfo":{"status":"ok","timestamp":1671040232906,"user_tz":300,"elapsed":2119,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"XIPkZheV02To","executionInfo":{"status":"ok","timestamp":1671044055177,"user_tz":300,"elapsed":283,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}},"outputId":"9d491251-7698-4ecd-9bfb-96a52c47bdb1"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["%ls /content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dOpy2cUnuvoY","executionInfo":{"status":"ok","timestamp":1671040147160,"user_tz":300,"elapsed":1214,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}},"outputId":"e0928b44-84cb-4906-f2e0-0839ecd05d29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mgdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBq9qgM_nuq-","outputId":"4576df12-f29f-49b9-f9eb-21acbbff305a","executionInfo":{"status":"ok","timestamp":1671040259649,"user_tz":300,"elapsed":280,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT\n"]}],"source":["%cd /content/gdrive/My Drive/I-BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JpQn5mcSn7F5","outputId":"da83cc90-85e2-4e48-e319-2787a125a6b7","executionInfo":{"status":"ok","timestamp":1671040269485,"user_tz":300,"elapsed":2651,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'I-BERT'...\n","^C\n"]}],"source":["#!git clone https://github.com/kssteven418/I-BERT.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3xkmyfM8n-dp","outputId":"eecc72e2-b8b3-4387-ee31-3a7e0e4091f6"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/coms6998_project/I-BERT\n"]}],"source":["#%cd I-BERT"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aW2HXlTGoAnZ","outputId":"5ea7c8fa-585a-4538-a5da-a3e55654da70","executionInfo":{"status":"ok","timestamp":1671040355742,"user_tz":300,"elapsed":57288,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Obtaining file:///content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq==0.9.0) (2022.6.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq==0.9.0) (1.13.0+cu116)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[K     |████████████████████████████████| 118 kB 6.9 MB/s \n","\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.8/dist-packages (from fairseq==0.9.0) (0.5.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq==0.9.0) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq==0.9.0) (4.64.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq==0.9.0) (0.29.32)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq==0.9.0) (1.15.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq==0.9.0) (2.21)\n","Collecting portalocker\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Collecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu->fairseq==0.9.0) (4.9.1)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu->fairseq==0.9.0) (0.8.10)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->fairseq==0.9.0) (4.4.0)\n","Installing collected packages: portalocker, colorama, sacrebleu, fairseq\n","  Running setup.py develop for fairseq\n","Successfully installed colorama-0.4.6 fairseq portalocker-2.6.0 sacrebleu-2.3.1\n"]}],"source":["!pip install --editable ./"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yavZbHhtpGpV","outputId":"161ce2d1-2fad-4f84-a62f-e7dadbe81b7b"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘models’: File exists\n"]}],"source":["%mkdir models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LpxrUEIPpqTw","outputId":"d2704eb7-704e-44e9-c2a3-3fcbe971b2fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/coms6998_project/I-BERT/models\n"]}],"source":["%cd models"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yd7GKNUbpRYV","outputId":"cf2ec6e8-c404-4a36-9b1a-dd552b534ed5"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-12-12 00:05:40--  https://dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 231160875 (220M) [application/gzip]\n","Saving to: ‘roberta.base.tar.gz’\n","\n","roberta.base.tar.gz 100%[===================>] 220.45M  56.9MB/s    in 4.7s    \n","\n","2022-12-12 00:05:45 (47.3 MB/s) - ‘roberta.base.tar.gz’ saved [231160875/231160875]\n","\n"]}],"source":["!wget https://dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5dbkZTnpU74","outputId":"5715f57e-8b0a-42b9-b07b-efc6d83c7b85"},"outputs":[{"name":"stdout","output_type":"stream","text":["roberta.base/\n","roberta.base/dict.txt\n","roberta.base/model.pt\n","roberta.base/NOTE\n"]}],"source":["!tar -xvf roberta.base.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5cTd7R4ypXLy","outputId":"591ba7a4-9c8c-4deb-bdf0-f294dbbd0685"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/MyDrive/coms6998_project/I-BERT\n"]}],"source":["%cd ..\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zej1oQIyp5kL","outputId":"a139162d-3b73-4a5d-a4be-8a2f32c6e1e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'GLUE-baselines'...\n","remote: Enumerating objects: 891, done.\u001b[K\n","remote: Counting objects: 100% (5/5), done.\u001b[K\n","remote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 891 (delta 1), reused 3 (delta 1), pack-reused 886\u001b[K\n","Receiving objects: 100% (891/891), 1.48 MiB | 8.74 MiB/s, done.\n","Resolving deltas: 100% (610/610), done.\n"]}],"source":["!git clone https://github.com/nyu-mll/GLUE-baselines.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"an0Txys-vPNh","outputId":"dbc54acf-e97d-4711-c80f-05e01ea55d9a"},"outputs":[{"name":"stdout","output_type":"stream","text":["python3: can't open file 'https://github.com/johnson7788/DeBERTa/blob/master/utils/download_glue_data.py': [Errno 2] No such file or directory\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I-X_jbuVqJ1X","outputId":"e0596d8a-3d09-40f9-ace6-e2661c4d4b17"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and extracting CoLA...\n","\tCompleted!\n","Downloading and extracting SST...\n","\tCompleted!\n","Processing MRPC...\n","\tError downloading standard development IDs for MRPC. You will need to manually split your data.\n","Downloading and extracting QQP...\n","\tCompleted!\n","Downloading and extracting STS...\n","\tCompleted!\n","Downloading and extracting MNLI...\n","\tNote (12/10/20): This script no longer downloads SNLI. You will need to manually download and format the data to use SNLI.\n","\tCompleted!\n","Downloading and extracting QNLI...\n","\tCompleted!\n","Downloading and extracting RTE...\n","\tCompleted!\n","Downloading and extracting WNLI...\n","\tCompleted!\n","Downloading and extracting diagnostic...\n","\tCompleted!\n"]}],"source":["!python GLUE-baselines/download_glue_data.py --data_dir glue_data --tasks all"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQPgZiZMqfKc","outputId":"7256b28e-4816-4f56-9ecb-de9066e576b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/coms6998_project/I-BERT\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G2Wa5dowujE5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9myoNv4UykY3","outputId":"e4451432-a1d2-4a0e-ad0d-ed980e28c2fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["/env/python\n"]}],"source":["!echo $PYTHONPATH"]},{"cell_type":"code","source":["!pip install fairseq"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d2Hxnc-HxxAa","executionInfo":{"status":"ok","timestamp":1671040560580,"user_tz":300,"elapsed":7750,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}},"outputId":"3981a04d-8952-40f3-bce2-c7cd1629e0c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fairseq\n","  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n","\u001b[K     |████████████████████████████████| 11.0 MB 9.8 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.13.0+cu116)\n","Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.13.0+cu116)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.15.1)\n","Collecting hydra-core<1.1,>=1.0.7\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 92.3 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq) (4.64.1)\n","Collecting omegaconf<2.1\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq) (2022.6.2)\n","Collecting bitarray\n","  Downloading bitarray-2.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 87.1 MB/s \n","\u001b[?25hRequirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.29.32)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.21.6)\n","Requirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.3.1)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 94.5 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.10.0)\n","Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (4.4.0)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.6.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq) (2.21)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.11.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=d5cf4d8cc4b210f1a50e78db4b014027272aaf2dc5a498773b4e1b68222d0444\n","  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: omegaconf, antlr4-python3-runtime, hydra-core, bitarray, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-2.6.0 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6\n"]}]},{"cell_type":"code","source":["import torch\n","print(torch.__version__)"],"metadata":{"id":"rUHFRR4RznFI"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDNpvrccqlFG","outputId":"6c2c5ef1-4ddb-476b-f545-00d7caed39e1","executionInfo":{"status":"ok","timestamp":1671040587066,"user_tz":300,"elapsed":20912,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-14 17:56:07--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n","HTTP request sent, awaiting response... 304 Not Modified\n","File ‘encoder.json’ not modified on server. Omitting download.\n","\n","--2022-12-14 17:56:08--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n","HTTP request sent, awaiting response... 304 Not Modified\n","File ‘vocab.bpe’ not modified on server. Omitting download.\n","\n","--2022-12-14 17:56:08--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 172.67.9.4, 104.22.75.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n","HTTP request sent, awaiting response... 304 Not Modified\n","File ‘dict.txt’ not modified on server. Omitting download.\n","\n","Preprocessing STS-B\n","Raw data as downloaded from glue website: glue_data/STS-B\n","BPE encoding train/input0\n","BPE encoding train/input1\n","BPE encoding dev/input0\n","BPE encoding dev/input1\n","BPE encoding test/input0\n","BPE encoding test/input1\n","Intel MKL FATAL ERROR: Cannot load /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_cpu.so.\n","Intel MKL FATAL ERROR: Cannot load /usr/local/lib/python3.8/dist-packages/torch/lib/libtorch_cpu.so.\n"]}],"source":["!bash ./examples/roberta/preprocess_GLUE_tasks.sh glue_data STS-B"]},{"cell_type":"code","source":["!bash ./examples/roberta/preprocess_GLUE_tasks.sh glue_data STS-B"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k7Wy6Gj-YQ29","outputId":"d44cc91c-99e3-4c3d-b2bd-90d358f8f587"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-13 16:48:00--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n","HTTP request sent, awaiting response... 304 Not Modified\n","File ‘encoder.json’ not modified on server. Omitting download.\n","\n","--2022-12-13 16:48:01--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n","HTTP request sent, awaiting response... 304 Not Modified\n","File ‘vocab.bpe’ not modified on server. Omitting download.\n","\n","--2022-12-13 16:48:01--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n","Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n","Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n","HTTP request sent, awaiting response... 304 Not Modified\n","File ‘dict.txt’ not modified on server. Omitting download.\n","\n","Preprocessing CoLA\n","Raw data as downloaded from glue website: glue_data/CoLA\n","BPE encoding train/input0\n","BPE encoding dev/input0\n","BPE encoding test/input0\n","2022-12-13 16:48:15 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2022-12-13 16:48:16 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='CoLA-bin/input0', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict='dict.txt', suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref='glue_data/CoLA/processed/test.input0', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='glue_data/CoLA/processed/train.input0', use_plasma_view=False, user_dir=None, validpref='glue_data/CoLA/processed/dev.input0', wandb_project=None, workers=60)\n","2022-12-13 16:48:16 | INFO | fairseq_cli.preprocess | [None] Dictionary: 50264 types\n","2022-12-13 16:48:18 | INFO | fairseq_cli.preprocess | [None] glue_data/CoLA/processed/train.input0: 8551 sents, 88681 tokens, 0.0% replaced (by <unk>)\n","2022-12-13 16:48:18 | INFO | fairseq_cli.preprocess | [None] Dictionary: 50264 types\n","2022-12-13 16:48:19 | INFO | fairseq_cli.preprocess | [None] glue_data/CoLA/processed/dev.input0: 1043 sents, 11079 tokens, 0.0% replaced (by <unk>)\n","2022-12-13 16:48:19 | INFO | fairseq_cli.preprocess | [None] Dictionary: 50264 types\n","2022-12-13 16:48:21 | INFO | fairseq_cli.preprocess | [None] glue_data/CoLA/processed/test.input0: 1063 sents, 11175 tokens, 0.0% replaced (by <unk>)\n","2022-12-13 16:48:21 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to CoLA-bin/input0\n","2022-12-13 16:48:24 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2022-12-13 16:48:24 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='CoLA-bin/label', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict=None, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='glue_data/CoLA/processed/train.label', use_plasma_view=False, user_dir=None, validpref='glue_data/CoLA/processed/dev.label', wandb_project=None, workers=60)\n","2022-12-13 16:48:25 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n","2022-12-13 16:48:26 | INFO | fairseq_cli.preprocess | [None] glue_data/CoLA/processed/train.label: 8551 sents, 17102 tokens, 0.0% replaced (by <unk>)\n","2022-12-13 16:48:26 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n","2022-12-13 16:48:27 | INFO | fairseq_cli.preprocess | [None] glue_data/CoLA/processed/dev.label: 1043 sents, 2086 tokens, 0.0% replaced (by <unk>)\n","2022-12-13 16:48:27 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to CoLA-bin/label\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3isIHKB3aqH","outputId":"6637174b-ad83-41f6-ee50-010f2f4e3bc7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fairseq\n","  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n","\u001b[K     |████████████████████████████████| 11.0 MB 4.6 MB/s \n","\u001b[?25hRequirement already satisfied: sacrebleu>=1.4.12 in /usr/local/lib/python3.8/dist-packages (from fairseq) (2.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fairseq) (4.64.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from fairseq) (2022.6.2)\n","Requirement already satisfied: cffi in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.15.1)\n","Collecting bitarray\n","  Downloading bitarray-2.6.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n","\u001b[K     |████████████████████████████████| 241 kB 92.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.29.32)\n","Collecting omegaconf<2.1\n","  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n","Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from fairseq) (0.13.0+cu116)\n","Collecting hydra-core<1.1,>=1.0.7\n","  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n","\u001b[K     |████████████████████████████████| 123 kB 90.7 MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from fairseq) (1.13.0+cu116)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq) (5.10.0)\n","Collecting antlr4-python3-runtime==4.8\n","  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 91.8 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (6.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from omegaconf<2.1->fairseq) (4.4.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (4.9.1)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (2.6.0)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu>=1.4.12->fairseq) (0.8.10)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi->fairseq) (2.21)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq) (3.11.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141231 sha256=c0c21f2b52958b8ca1b90118fc100be5ac19c442531015551a27e4ff3e99c24a\n","  Stored in directory: /root/.cache/pip/wheels/c8/d0/ab/d43c02eaddc5b9004db86950802442ad9a26f279c619e28da0\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: omegaconf, antlr4-python3-runtime, hydra-core, bitarray, fairseq\n","Successfully installed antlr4-python3-runtime-4.8 bitarray-2.6.0 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6\n"]}],"source":["!pip install fairseq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HihSTtmM3BlB"},"outputs":[],"source":["import fairseq"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdql5_zk4UKr"},"outputs":[],"source":["!git fetch"]},{"cell_type":"code","source":["!git branch -D ibert"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H6G_99PCd3EF","outputId":"5aed4ed8-fe7c-4f2a-e84a-5ed6f412d79f","executionInfo":{"status":"ok","timestamp":1671048777325,"user_tz":300,"elapsed":8,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["Deleted branch ibert (was 1b09c75).\n"]}]},{"cell_type":"code","source":["!git branch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9oaMj386doaF","outputId":"88033fbb-eecb-494b-9664-b044df01c845","executionInfo":{"status":"ok","timestamp":1671044641594,"user_tz":300,"elapsed":338,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"execution_count":62,"outputs":[{"output_type":"stream","name":"stdout","text":["  ibert\u001b[m\n","* \u001b[32mibert-base\u001b[m\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3CDlDBFD4XNl","outputId":"1256750e-63e9-4299-b808-bd9b48a8f86e","executionInfo":{"status":"ok","timestamp":1671042328272,"user_tz":300,"elapsed":461,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["M\texamples/joint_alignment_translation/prepare-wmt18en2de_no_norm_no_escape_no_agressive.sh\n","M\texamples/roberta/preprocess_GLUE_tasks.sh\n","M\texamples/roberta/preprocess_RACE.sh\n","M\texamples/speech_recognition/datasets/prepare-librispeech.sh\n","Branch 'ibert-base' set up to track remote branch 'ibert-base' from 'origin'.\n","Switched to a new branch 'ibert-base'\n"]}],"source":["!git checkout -t origin/ibert-base"]},{"cell_type":"code","source":[],"metadata":{"id":"eftvgE-fZLQ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wL8F9yvP4cm0","outputId":"8d3e1980-5a2b-450a-a373-31e55f3d6cb0","executionInfo":{"status":"ok","timestamp":1671047251780,"user_tz":300,"elapsed":2391169,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["valid_subset: valid\n","2022-12-14 19:07:44 | INFO | fairseq.tasks.text_to_speech | Please install tensorboardX: pip install tensorboardX\n","2022-12-14 19:07:46 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': 'outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742.log', 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4400, 'batch_size': 32, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4400, 'batch_size_valid': 32, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 12, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt', 'restore_file': 'models/roberta.base/model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='roberta_base', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_input=False, add_prev_output_tokens=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='roberta_base', attention_dropout=0.1, azureml_logging=False, batch_size=32, batch_size_valid=32, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', classification_head_name='sentence_classification_head', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='sentence_prediction', curriculum=0, data='SST-2-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eos=2, fast_stat_sync=False, ffn_blocks_to_remove=-1, ffn_reg_scale_factor=0.0, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file='outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742.log', log_format=None, log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=12, max_positions=512, max_source_positions=512, max_tokens=4400, max_tokens_valid=4400, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, mha_heads_to_keep=-1, mha_reg_scale_factor=0.0, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_shuffle=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_classes=2, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='models/roberta.base/model.pt', save_dir='outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, separator_token=2, shard_id=0, shorten_data_split_list='', shorten_method='none', skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, spectral_norm_classification_head=False, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='sentence_prediction', tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, total_num_update='20935', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=1256, weight_decay=0.1, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sentence_prediction', 'data': 'SST-2-bin', 'num_classes': 2, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': none, 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': False, 'classification_head_name': 'sentence_classification_head', 'seed': 1}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'sentence_classification_head', 'regression_target': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 1256, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 20935.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n","2022-12-14 19:07:47 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n","2022-12-14 19:07:47 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 9 types\n","2022-12-14 19:07:50 | INFO | fairseq_cli.train | RobertaModel(\n","  (encoder): RobertaEncoder(\n","    (sentence_encoder): TransformerEncoder(\n","      (dropout_module): FairseqDropout()\n","      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n","      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n","      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (layers): ModuleList(\n","        (0): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (1): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (2): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (3): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (4): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (5): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (6): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (7): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (8): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (9): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (10): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","        (11): TransformerEncoderLayerBase(\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n","            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n","          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n","          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        )\n","      )\n","    )\n","    (lm_head): RobertaLMHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (classification_heads): ModuleDict(\n","    (sentence_classification_head): RobertaClassificationHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","    )\n","  )\n",")\n","2022-12-14 19:07:50 | INFO | fairseq_cli.train | task: SentencePredictionTask\n","2022-12-14 19:07:50 | INFO | fairseq_cli.train | model: RobertaModel\n","2022-12-14 19:07:50 | INFO | fairseq_cli.train | criterion: SentencePredictionCriterion\n","2022-12-14 19:07:50 | INFO | fairseq_cli.train | num. shared model params: 210,306,395 (num. trained: 210,306,395)\n","2022-12-14 19:07:50 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n","2022-12-14 19:07:51 | INFO | fairseq.data.data_utils | loaded 872 examples from: SST-2-bin/input0/valid\n","2022-12-14 19:07:52 | INFO | fairseq.data.data_utils | loaded 872 examples from: SST-2-bin/label/valid\n","2022-12-14 19:07:52 | INFO | fairseq.tasks.sentence_prediction | Loaded valid with #samples: 872\n","2022-12-14 19:07:57 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\n","2022-12-14 19:07:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2022-12-14 19:07:57 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          \n","2022-12-14 19:07:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2022-12-14 19:07:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n","2022-12-14 19:07:57 | INFO | fairseq_cli.train | max tokens per device = 4400 and max sentences per device = 32\n","2022-12-14 19:07:57 | INFO | fairseq.trainer | Preparing to load checkpoint models/roberta.base/model.pt\n","2022-12-14 19:08:00 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.weight\n","2022-12-14 19:08:00 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.dense.bias\n","2022-12-14 19:08:00 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.weight\n","2022-12-14 19:08:00 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.sentence_classification_head.out_proj.bias\n","2022-12-14 19:08:01 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp\n","2022-12-14 19:08:01 | INFO | fairseq.trainer | Loaded checkpoint models/roberta.base/model.pt (epoch 1 @ 0 updates)\n","2022-12-14 19:08:01 | INFO | fairseq.trainer | loading train data for epoch 1\n","2022-12-14 19:08:02 | INFO | fairseq.data.data_utils | loaded 67,349 examples from: SST-2-bin/input0/train\n","2022-12-14 19:08:03 | INFO | fairseq.data.data_utils | loaded 67,349 examples from: SST-2-bin/label/train\n","2022-12-14 19:08:03 | INFO | fairseq.tasks.sentence_prediction | Loaded train with #samples: 67349\n","2022-12-14 19:08:03 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 001:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:08:03 | INFO | fairseq.trainer | begin training epoch 1\n","2022-12-14 19:08:03 | INFO | fairseq_cli.train | Start iterating over samples\n","/usr/local/lib/python3.8/dist-packages/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n","  warnings.warn(\n","epoch 001: 100% 2103/2105 [02:50<00:00, 12.21it/s, loss=0.31, nll_loss=0.023, accuracy=91.7, wps=5384.5, ups=12.61, wpb=426.9, bsz=32, num_updates=2100, lr=9.57112e-06, gnorm=11.983, train_wall=8, gb_free=36.7, wall=177]2022-12-14 19:10:54 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 001 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  11% 3/28 [00:00<00:00, 25.36it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  25% 7/28 [00:00<00:00, 32.76it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  43% 12/28 [00:00<00:00, 37.16it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  57% 16/28 [00:00<00:00, 37.82it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  75% 21/28 [00:00<00:00, 38.80it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  93% 26/28 [00:00<00:00, 40.41it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:10:55 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.284 | nll_loss 0.011 | accuracy 92.8 | wps 31904.7 | wpb 778.9 | bsz 31.1 | num_updates 2105\n","2022-12-14 19:10:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 2105 updates\n","2022-12-14 19:10:55 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint1.pt\n","2022-12-14 19:11:06 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint1.pt\n","epoch 001: 100% 2103/2105 [03:10<00:00, 12.21it/s, loss=0.31, nll_loss=0.023, accuracy=91.7, wps=5384.5, ups=12.61, wpb=426.9, bsz=32, num_updates=2100, lr=9.57112e-06, gnorm=11.983, train_wall=8, gb_free=36.7, wall=177]2022-12-14 19:11:18 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint1.pt (epoch 1 @ 2105 updates, score 92.8) (writing took 23.33762432599997 seconds)\n","2022-12-14 19:11:18 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n","2022-12-14 19:11:18 | INFO | train | epoch 001 | loss 0.436 | nll_loss 0.033 | accuracy 86 | wps 4712.1 | ups 11.02 | wpb 427.4 | bsz 32 | num_updates 2105 | lr 9.56858e-06 | gnorm 13.292 | train_wall 166 | gb_free 37.1 | wall 202\n","2022-12-14 19:11:18 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 002:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:11:19 | INFO | fairseq.trainer | begin training epoch 2\n","2022-12-14 19:11:19 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 002: 100% 2104/2105 [02:52<00:00, 13.08it/s, loss=0.228, nll_loss=0.017, accuracy=94.2, wps=5345.3, ups=12.78, wpb=418.1, bsz=32, num_updates=4200, lr=8.50399e-06, gnorm=10.598, train_wall=8, gb_free=37.2, wall=374]2022-12-14 19:14:11 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 002 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:   7% 2/28 [00:00<00:01, 17.22it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  25% 7/28 [00:00<00:00, 31.64it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  43% 12/28 [00:00<00:00, 36.81it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  57% 16/28 [00:00<00:00, 37.41it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  75% 21/28 [00:00<00:00, 38.48it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  93% 26/28 [00:00<00:00, 40.19it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:14:12 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.309 | nll_loss 0.012 | accuracy 93 | wps 32524.1 | wpb 778.9 | bsz 31.1 | num_updates 4210 | best_accuracy 93\n","2022-12-14 19:14:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 4210 updates\n","2022-12-14 19:14:12 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint2.pt\n","2022-12-14 19:14:18 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint2.pt\n","epoch 002: 100% 2104/2105 [03:04<00:00, 13.08it/s, loss=0.228, nll_loss=0.017, accuracy=94.2, wps=5345.3, ups=12.78, wpb=418.1, bsz=32, num_updates=4200, lr=8.50399e-06, gnorm=10.598, train_wall=8, gb_free=37.2, wall=374]2022-12-14 19:14:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint2.pt (epoch 2 @ 4210 updates, score 93.0) (writing took 20.761277321000307 seconds)\n","2022-12-14 19:14:33 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n","2022-12-14 19:14:33 | INFO | train | epoch 002 | loss 0.228 | nll_loss 0.017 | accuracy 94.1 | wps 4629.5 | ups 10.83 | wpb 427.4 | bsz 32 | num_updates 4210 | lr 8.49891e-06 | gnorm 11.099 | train_wall 168 | gb_free 36.7 | wall 396\n","2022-12-14 19:14:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 003:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:14:33 | INFO | fairseq.trainer | begin training epoch 3\n","2022-12-14 19:14:33 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 003: 100% 2104/2105 [02:58<00:00, 13.10it/s, loss=0.173, nll_loss=0.013, accuracy=95.7, wps=5383.2, ups=12.58, wpb=427.8, bsz=32, num_updates=6300, lr=7.43686e-06, gnorm=9.556, train_wall=8, gb_free=37.1, wall=573]2022-12-14 19:17:31 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 003 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:   4% 1/28 [00:00<00:02,  9.74it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  18% 5/28 [00:00<00:00, 26.62it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  36% 10/28 [00:00<00:00, 34.77it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  54% 15/28 [00:00<00:00, 37.33it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  68% 19/28 [00:00<00:00, 38.03it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  86% 24/28 [00:00<00:00, 39.20it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:17:32 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 0.255 | nll_loss 0.01 | accuracy 94.6 | wps 32309 | wpb 778.9 | bsz 31.1 | num_updates 6315 | best_accuracy 94.6\n","2022-12-14 19:17:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 6315 updates\n","2022-12-14 19:17:32 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint3.pt\n","2022-12-14 19:17:43 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint3.pt\n","epoch 003: 100% 2104/2105 [03:10<00:00, 13.10it/s, loss=0.173, nll_loss=0.013, accuracy=95.7, wps=5383.2, ups=12.58, wpb=427.8, bsz=32, num_updates=6300, lr=7.43686e-06, gnorm=9.556, train_wall=8, gb_free=37.1, wall=573]2022-12-14 19:17:59 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint3.pt (epoch 3 @ 6315 updates, score 94.6) (writing took 26.94753163399946 seconds)\n","2022-12-14 19:17:59 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n","2022-12-14 19:17:59 | INFO | train | epoch 003 | loss 0.17 | nll_loss 0.013 | accuracy 95.8 | wps 4366.3 | ups 10.22 | wpb 427.4 | bsz 32 | num_updates 6315 | lr 7.42924e-06 | gnorm 9.721 | train_wall 173 | gb_free 37.1 | wall 602\n","2022-12-14 19:17:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 004:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:17:59 | INFO | fairseq.trainer | begin training epoch 4\n","2022-12-14 19:17:59 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 004: 100% 2103/2105 [02:47<00:00, 12.64it/s, loss=0.119, nll_loss=0.009, accuracy=97.2, wps=5238.7, ups=12.42, wpb=421.6, bsz=32, num_updates=8400, lr=6.36973e-06, gnorm=8.888, train_wall=8, gb_free=36.7, wall=768]2022-12-14 19:20:47 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 004 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:   7% 2/28 [00:00<00:01, 16.38it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  21% 6/28 [00:00<00:00, 28.34it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  39% 11/28 [00:00<00:00, 34.82it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  54% 15/28 [00:00<00:00, 36.23it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  68% 19/28 [00:00<00:00, 37.28it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  86% 24/28 [00:00<00:00, 38.69it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:20:47 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 0.296 | nll_loss 0.012 | accuracy 94 | wps 31624.6 | wpb 778.9 | bsz 31.1 | num_updates 8420 | best_accuracy 94.6\n","2022-12-14 19:20:47 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 8420 updates\n","2022-12-14 19:20:47 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint4.pt\n","2022-12-14 19:20:54 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint4.pt\n","2022-12-14 19:21:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint4.pt (epoch 4 @ 8420 updates, score 94.0) (writing took 13.317317738000384 seconds)\n","2022-12-14 19:21:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n","2022-12-14 19:21:01 | INFO | train | epoch 004 | loss 0.133 | nll_loss 0.01 | accuracy 96.7 | wps 4950.2 | ups 11.58 | wpb 427.4 | bsz 32 | num_updates 8420 | lr 6.35957e-06 | gnorm 9.223 | train_wall 162 | gb_free 37.2 | wall 784\n","2022-12-14 19:21:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 005:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:21:02 | INFO | fairseq.trainer | begin training epoch 5\n","2022-12-14 19:21:02 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 005: 100% 2103/2105 [03:02<00:00, 13.21it/s, loss=0.099, nll_loss=0.008, accuracy=97.8, wps=5287, ups=12.55, wpb=421.3, bsz=32, num_updates=10500, lr=5.30261e-06, gnorm=7.956, train_wall=8, gb_free=36.8, wall=966]2022-12-14 19:24:05 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 005 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:   7% 2/28 [00:00<00:01, 18.76it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  25% 7/28 [00:00<00:00, 32.79it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  43% 12/28 [00:00<00:00, 37.56it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  57% 16/28 [00:00<00:00, 38.02it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  75% 21/28 [00:00<00:00, 38.76it/s]\u001b[A\n","epoch 005 | valid on 'valid' subset:  93% 26/28 [00:00<00:00, 40.22it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:24:06 | INFO | valid | epoch 005 | valid on 'valid' subset | loss 0.313 | nll_loss 0.013 | accuracy 94 | wps 32389.6 | wpb 778.9 | bsz 31.1 | num_updates 10525 | best_accuracy 94.6\n","2022-12-14 19:24:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 10525 updates\n","2022-12-14 19:24:06 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint5.pt\n","2022-12-14 19:24:17 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint5.pt\n","2022-12-14 19:24:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint5.pt (epoch 5 @ 10525 updates, score 94.0) (writing took 17.71691580999959 seconds)\n","2022-12-14 19:24:23 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)\n","2022-12-14 19:24:23 | INFO | train | epoch 005 | loss 0.104 | nll_loss 0.008 | accuracy 97.4 | wps 4437.9 | ups 10.38 | wpb 427.4 | bsz 32 | num_updates 10525 | lr 5.2899e-06 | gnorm 8.383 | train_wall 178 | gb_free 36.9 | wall 987\n","2022-12-14 19:24:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 006:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:24:24 | INFO | fairseq.trainer | begin training epoch 6\n","2022-12-14 19:24:24 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 006: 100% 2103/2105 [02:52<00:00, 12.83it/s, loss=0.079, nll_loss=0.006, accuracy=98.1, wps=5474.2, ups=12.95, wpb=422.8, bsz=32, num_updates=12600, lr=4.23548e-06, gnorm=7.492, train_wall=7, gb_free=37.2, wall=1157]2022-12-14 19:27:16 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 006 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:   4% 1/28 [00:00<00:02,  9.99it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  18% 5/28 [00:00<00:00, 26.94it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  36% 10/28 [00:00<00:00, 35.02it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  54% 15/28 [00:00<00:00, 37.27it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  68% 19/28 [00:00<00:00, 37.84it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset:  82% 23/28 [00:00<00:00, 38.34it/s]\u001b[A\n","epoch 006 | valid on 'valid' subset: 100% 28/28 [00:00<00:00, 41.10it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:27:17 | INFO | valid | epoch 006 | valid on 'valid' subset | loss 0.357 | nll_loss 0.014 | accuracy 94 | wps 31850.1 | wpb 778.9 | bsz 31.1 | num_updates 12630 | best_accuracy 94.6\n","2022-12-14 19:27:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 12630 updates\n","2022-12-14 19:27:17 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint6.pt\n","2022-12-14 19:27:28 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint6.pt\n","epoch 006: 100% 2103/2105 [03:09<00:00, 12.83it/s, loss=0.079, nll_loss=0.006, accuracy=98.1, wps=5474.2, ups=12.95, wpb=422.8, bsz=32, num_updates=12600, lr=4.23548e-06, gnorm=7.492, train_wall=7, gb_free=37.2, wall=1157]2022-12-14 19:27:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint6.pt (epoch 6 @ 12630 updates, score 94.0) (writing took 17.640976798999873 seconds)\n","2022-12-14 19:27:35 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)\n","2022-12-14 19:27:35 | INFO | train | epoch 006 | loss 0.085 | nll_loss 0.006 | accuracy 97.9 | wps 4706 | ups 11.01 | wpb 427.4 | bsz 32 | num_updates 12630 | lr 4.22023e-06 | gnorm 8.175 | train_wall 167 | gb_free 36.9 | wall 1178\n","2022-12-14 19:27:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 007:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:27:37 | INFO | fairseq.trainer | begin training epoch 7\n","2022-12-14 19:27:37 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 007: 100% 2103/2105 [02:47<00:00, 13.28it/s, loss=0.07, nll_loss=0.005, accuracy=98.1, wps=5404.2, ups=12.65, wpb=427, bsz=32, num_updates=14700, lr=3.16835e-06, gnorm=9.895, train_wall=8, gb_free=37, wall=1345]2022-12-14 19:30:24 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 007 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 007 | valid on 'valid' subset:   7% 2/28 [00:00<00:01, 17.69it/s]\u001b[A\n","epoch 007 | valid on 'valid' subset:  21% 6/28 [00:00<00:00, 29.47it/s]\u001b[A\n","epoch 007 | valid on 'valid' subset:  39% 11/28 [00:00<00:00, 36.17it/s]\u001b[A\n","epoch 007 | valid on 'valid' subset:  57% 16/28 [00:00<00:00, 37.53it/s]\u001b[A\n","epoch 007 | valid on 'valid' subset:  75% 21/28 [00:00<00:00, 38.59it/s]\u001b[A\n","epoch 007 | valid on 'valid' subset:  93% 26/28 [00:00<00:00, 40.22it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:30:25 | INFO | valid | epoch 007 | valid on 'valid' subset | loss 0.347 | nll_loss 0.014 | accuracy 94.4 | wps 32119.2 | wpb 778.9 | bsz 31.1 | num_updates 14735 | best_accuracy 94.6\n","2022-12-14 19:30:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 14735 updates\n","2022-12-14 19:30:25 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint7.pt\n","2022-12-14 19:30:41 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint7.pt\n","epoch 007: 100% 2103/2105 [03:06<00:00, 13.28it/s, loss=0.07, nll_loss=0.005, accuracy=98.1, wps=5404.2, ups=12.65, wpb=427, bsz=32, num_updates=14700, lr=3.16835e-06, gnorm=9.895, train_wall=8, gb_free=37, wall=1345]2022-12-14 19:30:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint7.pt (epoch 7 @ 14735 updates, score 94.4) (writing took 25.440493164000145 seconds)\n","2022-12-14 19:30:50 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)\n","2022-12-14 19:30:50 | INFO | train | epoch 007 | loss 0.068 | nll_loss 0.005 | accuracy 98.3 | wps 4593.3 | ups 10.75 | wpb 427.4 | bsz 32 | num_updates 14735 | lr 3.15057e-06 | gnorm 7.719 | train_wall 162 | gb_free 36.9 | wall 1374\n","2022-12-14 19:30:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 008:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:30:51 | INFO | fairseq.trainer | begin training epoch 8\n","2022-12-14 19:30:51 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 008: 100% 2104/2105 [02:48<00:00, 13.57it/s, loss=0.068, nll_loss=0.005, accuracy=98.3, wps=5297, ups=12.24, wpb=432.7, bsz=32, num_updates=16800, lr=2.10122e-06, gnorm=8.032, train_wall=8, gb_free=37.1, wall=1539]2022-12-14 19:33:39 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 008 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 008 | valid on 'valid' subset:   7% 2/28 [00:00<00:01, 16.52it/s]\u001b[A\n","epoch 008 | valid on 'valid' subset:  21% 6/28 [00:00<00:00, 29.19it/s]\u001b[A\n","epoch 008 | valid on 'valid' subset:  39% 11/28 [00:00<00:00, 36.29it/s]\u001b[A\n","epoch 008 | valid on 'valid' subset:  57% 16/28 [00:00<00:00, 37.62it/s]\u001b[A\n","epoch 008 | valid on 'valid' subset:  75% 21/28 [00:00<00:00, 38.65it/s]\u001b[A\n","epoch 008 | valid on 'valid' subset:  93% 26/28 [00:00<00:00, 40.24it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:33:40 | INFO | valid | epoch 008 | valid on 'valid' subset | loss 0.353 | nll_loss 0.014 | accuracy 94.7 | wps 32462.4 | wpb 778.9 | bsz 31.1 | num_updates 16840 | best_accuracy 94.7\n","2022-12-14 19:33:40 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 16840 updates\n","2022-12-14 19:33:40 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint8.pt\n","2022-12-14 19:33:51 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint8.pt\n","epoch 008: 100% 2104/2105 [03:02<00:00, 13.57it/s, loss=0.068, nll_loss=0.005, accuracy=98.3, wps=5297, ups=12.24, wpb=432.7, bsz=32, num_updates=16800, lr=2.10122e-06, gnorm=8.032, train_wall=8, gb_free=37.1, wall=1539]2022-12-14 19:34:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint8.pt (epoch 8 @ 16840 updates, score 94.7) (writing took 24.44736325299982 seconds)\n","2022-12-14 19:34:04 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)\n","2022-12-14 19:34:04 | INFO | train | epoch 008 | loss 0.057 | nll_loss 0.004 | accuracy 98.5 | wps 4640.5 | ups 10.86 | wpb 427.4 | bsz 32 | num_updates 16840 | lr 2.0809e-06 | gnorm 7.213 | train_wall 163 | gb_free 36.8 | wall 1568\n","2022-12-14 19:34:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 009:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:34:05 | INFO | fairseq.trainer | begin training epoch 9\n","2022-12-14 19:34:05 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 009: 100% 2103/2105 [02:57<00:00, 12.86it/s, loss=0.044, nll_loss=0.003, accuracy=98.8, wps=5354.8, ups=12.51, wpb=428, bsz=32, num_updates=18900, lr=1.0341e-06, gnorm=6.324, train_wall=8, gb_free=36.8, wall=1742]2022-12-14 19:37:03 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 009 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 009 | valid on 'valid' subset:   7% 2/28 [00:00<00:01, 17.88it/s]\u001b[A\n","epoch 009 | valid on 'valid' subset:  21% 6/28 [00:00<00:00, 30.09it/s]\u001b[A\n","epoch 009 | valid on 'valid' subset:  39% 11/28 [00:00<00:00, 36.51it/s]\u001b[A\n","epoch 009 | valid on 'valid' subset:  57% 16/28 [00:00<00:00, 37.56it/s]\u001b[A\n","epoch 009 | valid on 'valid' subset:  75% 21/28 [00:00<00:00, 38.36it/s]\u001b[A\n","epoch 009 | valid on 'valid' subset:  93% 26/28 [00:00<00:00, 39.96it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:37:03 | INFO | valid | epoch 009 | valid on 'valid' subset | loss 0.376 | nll_loss 0.015 | accuracy 94.7 | wps 32042 | wpb 778.9 | bsz 31.1 | num_updates 18945 | best_accuracy 94.7\n","2022-12-14 19:37:03 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 18945 updates\n","2022-12-14 19:37:03 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint9.pt\n","epoch 009: 100% 2103/2105 [03:08<00:00, 12.86it/s, loss=0.044, nll_loss=0.003, accuracy=98.8, wps=5354.8, ups=12.51, wpb=428, bsz=32, num_updates=18900, lr=1.0341e-06, gnorm=6.324, train_wall=8, gb_free=36.8, wall=1742]2022-12-14 19:37:15 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint9.pt\n","2022-12-14 19:37:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint9.pt (epoch 9 @ 18945 updates, score 94.7) (writing took 25.994786939999358 seconds)\n","2022-12-14 19:37:29 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)\n","2022-12-14 19:37:29 | INFO | train | epoch 009 | loss 0.05 | nll_loss 0.004 | accuracy 98.7 | wps 4390.6 | ups 10.27 | wpb 427.4 | bsz 32 | num_updates 18945 | lr 1.01123e-06 | gnorm 6.955 | train_wall 173 | gb_free 37.2 | wall 1773\n","2022-12-14 19:37:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 010:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:37:29 | INFO | fairseq.trainer | begin training epoch 10\n","2022-12-14 19:37:29 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 010: 100% 2103/2105 [02:52<00:00, 12.75it/s, loss=0.041, nll_loss=0.003, accuracy=99, wps=5327.7, ups=12.58, wpb=423.5, bsz=32, num_updates=21000, lr=0, gnorm=6.436, train_wall=8, gb_free=37.2, wall=1942]2022-12-14 19:40:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 010 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 010 | valid on 'valid' subset:   4% 1/28 [00:00<00:02,  9.84it/s]\u001b[A\n","epoch 010 | valid on 'valid' subset:  18% 5/28 [00:00<00:00, 27.26it/s]\u001b[A\n","epoch 010 | valid on 'valid' subset:  36% 10/28 [00:00<00:00, 34.28it/s]\u001b[A\n","epoch 010 | valid on 'valid' subset:  54% 15/28 [00:00<00:00, 37.05it/s]\u001b[A\n","epoch 010 | valid on 'valid' subset:  68% 19/28 [00:00<00:00, 37.93it/s]\u001b[A\n","epoch 010 | valid on 'valid' subset:  86% 24/28 [00:00<00:00, 39.23it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:40:23 | INFO | valid | epoch 010 | valid on 'valid' subset | loss 0.387 | nll_loss 0.015 | accuracy 95 | wps 32070.3 | wpb 778.9 | bsz 31.1 | num_updates 21050 | best_accuracy 95\n","2022-12-14 19:40:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 21050 updates\n","2022-12-14 19:40:23 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint10.pt\n","epoch 010: 100% 2103/2105 [03:04<00:00, 12.75it/s, loss=0.041, nll_loss=0.003, accuracy=99, wps=5327.7, ups=12.58, wpb=423.5, bsz=32, num_updates=21000, lr=0, gnorm=6.436, train_wall=8, gb_free=37.2, wall=1942]2022-12-14 19:40:34 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint10.pt\n","2022-12-14 19:40:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint10.pt (epoch 10 @ 21050 updates, score 95.0) (writing took 25.707516755000142 seconds)\n","2022-12-14 19:40:49 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)\n","2022-12-14 19:40:49 | INFO | train | epoch 010 | loss 0.042 | nll_loss 0.003 | accuracy 99 | wps 4512.6 | ups 10.56 | wpb 427.4 | bsz 32 | num_updates 21050 | lr 0 | gnorm 6.591 | train_wall 168 | gb_free 37.1 | wall 1972\n","2022-12-14 19:40:49 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 011:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:40:49 | INFO | fairseq.trainer | begin training epoch 11\n","2022-12-14 19:40:49 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 011: 100% 2103/2105 [02:47<00:00, 13.28it/s, loss=0.041, nll_loss=0.003, accuracy=99.1, wps=5142.2, ups=12.11, wpb=424.7, bsz=32, num_updates=23100, lr=0, gnorm=6.353, train_wall=8, gb_free=37.1, wall=2136]2022-12-14 19:43:37 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 011 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 011 | valid on 'valid' subset:   7% 2/28 [00:00<00:01, 18.41it/s]\u001b[A\n","epoch 011 | valid on 'valid' subset:  21% 6/28 [00:00<00:00, 30.65it/s]\u001b[A\n","epoch 011 | valid on 'valid' subset:  39% 11/28 [00:00<00:00, 37.06it/s]\u001b[A\n","epoch 011 | valid on 'valid' subset:  57% 16/28 [00:00<00:00, 38.17it/s]\u001b[A\n","epoch 011 | valid on 'valid' subset:  75% 21/28 [00:00<00:00, 39.06it/s]\u001b[A\n","epoch 011 | valid on 'valid' subset:  93% 26/28 [00:00<00:00, 40.61it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:43:37 | INFO | valid | epoch 011 | valid on 'valid' subset | loss 0.387 | nll_loss 0.015 | accuracy 95 | wps 32472.9 | wpb 778.9 | bsz 31.1 | num_updates 23155 | best_accuracy 95\n","2022-12-14 19:43:37 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 23155 updates\n","2022-12-14 19:43:37 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint11.pt\n","2022-12-14 19:43:44 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint11.pt\n","epoch 011: 100% 2103/2105 [03:04<00:00, 13.28it/s, loss=0.041, nll_loss=0.003, accuracy=99.1, wps=5142.2, ups=12.11, wpb=424.7, bsz=32, num_updates=23100, lr=0, gnorm=6.353, train_wall=8, gb_free=37.1, wall=2136]2022-12-14 19:43:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint11.pt (epoch 11 @ 23155 updates, score 95.0) (writing took 21.101773213999877 seconds)\n","2022-12-14 19:43:58 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)\n","2022-12-14 19:43:58 | INFO | train | epoch 011 | loss 0.038 | nll_loss 0.003 | accuracy 99 | wps 4742 | ups 11.09 | wpb 427.4 | bsz 32 | num_updates 23155 | lr 0 | gnorm 5.946 | train_wall 162 | gb_free 36.9 | wall 2162\n","2022-12-14 19:43:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2105\n","epoch 012:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 19:43:59 | INFO | fairseq.trainer | begin training epoch 12\n","2022-12-14 19:43:59 | INFO | fairseq_cli.train | Start iterating over samples\n","epoch 012: 100% 2103/2105 [03:01<00:00, 13.64it/s, loss=0.04, nll_loss=0.003, accuracy=99.1, wps=5431.8, ups=12.39, wpb=438.3, bsz=32, num_updates=25200, lr=0, gnorm=5.996, train_wall=8, gb_free=36.9, wall=2339]2022-12-14 19:47:01 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 012 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 012 | valid on 'valid' subset:   7% 2/28 [00:00<00:01, 16.85it/s]\u001b[A\n","epoch 012 | valid on 'valid' subset:  25% 7/28 [00:00<00:00, 31.42it/s]\u001b[A\n","epoch 012 | valid on 'valid' subset:  43% 12/28 [00:00<00:00, 36.51it/s]\u001b[A\n","epoch 012 | valid on 'valid' subset:  57% 16/28 [00:00<00:00, 37.19it/s]\u001b[A\n","epoch 012 | valid on 'valid' subset:  75% 21/28 [00:00<00:00, 38.19it/s]\u001b[A\n","epoch 012 | valid on 'valid' subset:  93% 26/28 [00:00<00:00, 39.82it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 19:47:01 | INFO | valid | epoch 012 | valid on 'valid' subset | loss 0.387 | nll_loss 0.015 | accuracy 95 | wps 32009.7 | wpb 778.9 | bsz 31.1 | num_updates 25260 | best_accuracy 95\n","2022-12-14 19:47:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 25260 updates\n","2022-12-14 19:47:01 | INFO | fairseq.trainer | Saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint12.pt\n","2022-12-14 19:47:13 | INFO | fairseq.trainer | Finished saving checkpoint to /content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint12.pt\n","epoch 012: 100% 2103/2105 [03:14<00:00, 13.64it/s, loss=0.04, nll_loss=0.003, accuracy=99.1, wps=5431.8, ups=12.39, wpb=438.3, bsz=32, num_updates=25200, lr=0, gnorm=5.996, train_wall=8, gb_free=36.9, wall=2339]2022-12-14 19:47:26 | INFO | fairseq.checkpoint_utils | Saved checkpoint outputs/none/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-5/1214-190742_ckpt/checkpoint12.pt (epoch 12 @ 25260 updates, score 95.0) (writing took 24.488142348999645 seconds)\n","2022-12-14 19:47:26 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)\n","2022-12-14 19:47:26 | INFO | train | epoch 012 | loss 0.04 | nll_loss 0.003 | accuracy 99 | wps 4337.5 | ups 10.15 | wpb 427.4 | bsz 32 | num_updates 25260 | lr 0 | gnorm 6.257 | train_wall 177 | gb_free 36.9 | wall 2369\n","2022-12-14 19:47:26 | INFO | fairseq_cli.train | done training in 2362.5 seconds\n"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run.py --arch roberta_base --task SST-2"]},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"me3f1Y4wPpuK","executionInfo":{"status":"ok","timestamp":1671048384425,"user_tz":300,"elapsed":360,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}},"outputId":"9357662d-7032-4c6d-87ca-6deaacf2903c"},"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["!git stash"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kpNpVS3-RzhV","executionInfo":{"status":"ok","timestamp":1671048953086,"user_tz":300,"elapsed":976,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}},"outputId":"6ffb85c1-39e5-4d21-9839-3e4bdb99c4ce"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","*** Please tell me who you are.\n","\n","Run\n","\n","  git config --global user.email \"you@example.com\"\n","  git config --global user.name \"Your Name\"\n","\n","to set your account's default identity.\n","Omit --global to set the identity only in this repository.\n","\n","fatal: unable to auto-detect email address (got 'root@3226f4fca170.(none)')\n","Cannot save the current index state\n"]}]},{"cell_type":"code","execution_count":76,"metadata":{"id":"TvxNmORj4mRr","colab":{"base_uri":"https://localhost:8080/"},"outputId":"48838dc2-ec70-4cad-bd55-f35accbca02a","executionInfo":{"status":"ok","timestamp":1671049710527,"user_tz":300,"elapsed":201,"user":{"displayName":"Yiquan Li","userId":"17834347692884706566"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Switched to a new branch 'ibert'\n"]}],"source":["!git checkout -f -b ibert"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ub31w6M44q5I","colab":{"base_uri":"https://localhost:8080/"},"outputId":"781dcbbe-8e55-4e6c-cc28-29aeb763bad1"},"outputs":[{"output_type":"stream","name":"stdout","text":["valid_subset: valid\n","valid_interval_updates: None\n","Finetuning from the checkpoint: checkpoint_best_SST-2.pt\n","2022-12-14 20:30:54 | INFO | fairseq_cli.train | Namespace(activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, add_prev_output_tokens=False, all_gather_list_size=16384, arch='roberta_base', attention_dropout=0.1, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_suffix='', classification_head_name='sentence_classification_head', clip_norm=0.0, cpu=False, criterion='sentence_prediction', curriculum=0, data='SST-2-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', dropout=0.1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, end_learning_rate=0.0, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, force_dequant='none', fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_last_epochs=-1, localsgd_frequency=3, log_file='outputs/symmetric/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-06/1214-203051.log', log_format=None, log_interval=100, lr=[1e-06], lr_scheduler='polynomial_decay', max_epoch=12, max_positions=512, max_sentences=32, max_sentences_valid=32, max_tokens=4400, max_tokens_valid=4400, max_update=0, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, min_lr=-1, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_save=False, no_save_optimizer_state=False, no_seed_provided=True, no_shuffle=False, nprocs_per_node=1, num_classes=2, num_workers=1, optimizer='adam', optimizer_overrides='{}', patience=-1, pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_mode='symmetric', quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, required_batch_size_multiple=1, reset_dataloader=True, reset_lr_scheduler=True, reset_meters=True, reset_optimizer=True, restore_file='checkpoint_best_SST-2.pt', save_dir='outputs/symmetric/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-06/1214-203051_ckpt', save_interval=1, save_interval_updates=0, seed=1, sentence_avg=False, separator_token=2, shorten_data_split_list='', shorten_method='none', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_time_hours=0, task='sentence_prediction', tensorboard_logdir='', threshold_loss_scale=None, tokenizer=None, total_num_update=20935, tpu=False, train_subset='train', update_freq=[1], use_bmuf=False, use_old_adam=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, weight_decay=0.1)\n","2022-12-14 20:30:54 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n","2022-12-14 20:30:54 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 9 types\n","2022-12-14 20:30:54 | INFO | fairseq.data.data_utils | loaded 872 examples from: SST-2-bin/input0/valid\n","2022-12-14 20:30:54 | INFO | fairseq.data.data_utils | loaded 872 examples from: SST-2-bin/label/valid\n","2022-12-14 20:30:54 | INFO | fairseq.tasks.sentence_prediction | Loaded valid with #samples: 872\n","2022-12-14 20:30:54 | INFO | fairseq.modules.transformer_sentence_encoder | Dropout 0.1, attn dropout 0.1, act dropout 0.0\n","2022-12-14 20:30:55 | INFO | fairseq_cli.train | RobertaModel(\n","  (encoder): RobertaEncoder(\n","    (sentence_encoder): TransformerSentenceEncoder(\n","      (dropout_module): FairseqDropout()\n","      (embed_tokens): QuantEmbedding()\n","      (embed_positions): QuantEmbedding()\n","      (embed_positions_act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","      (layers): ModuleList(\n","        (0): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (1): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (2): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (3): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (4): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (5): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (6): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (7): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (8): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (9): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (10): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","        (11): TransformerSentenceEncoderLayer(\n","          (dropout_module): FairseqDropout()\n","          (activation_dropout_module): FairseqDropout()\n","          (activation_fn_approx): IntGELU()\n","          (input_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn): MultiheadAttention(\n","            (dropout_module): FairseqDropout()\n","            (k_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (v_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (q_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","            (k_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (v_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (q_proj_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (softmax): IntSoftmax(\n","              (act): QuantAct(activation_bit=16, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            )\n","            (attn_probs_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (attn_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","            (out_proj): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          )\n","          (pre_self_attn_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (self_attn_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","          (fc1_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc2_act): QuantAct(activation_bit=8, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (fc1): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (fc2): (QuantLinear() weight_bit=8, quant_mode=symmetric)\n","          (pre_final_layer_norm_act): QuantAct(activation_bit=22, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          (final_layer_norm): IntLayerNorm(\n","            (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","          )\n","        )\n","      )\n","      (emb_layer_norm): IntLayerNorm(\n","        (activation): QuantAct(activation_bit=32, quant_mode: symmetric, Act_min: 0.00, Act_max: 0.00)\n","      )\n","    )\n","    (lm_head): RobertaLMHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (classification_heads): ModuleDict(\n","    (sentence_classification_head): RobertaClassificationHead(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (dropout): Dropout(p=0.0, inplace=False)\n","      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n","    )\n","  )\n",")\n","2022-12-14 20:30:55 | INFO | fairseq_cli.train | task: sentence_prediction (SentencePredictionTask)\n","2022-12-14 20:30:55 | INFO | fairseq_cli.train | model: roberta_base (RobertaModel)\n","2022-12-14 20:30:55 | INFO | fairseq_cli.train | criterion: sentence_prediction (SentencePredictionCriterion)\n","2022-12-14 20:30:55 | INFO | fairseq_cli.train | num. model params: 125288795 (num. trained: 125288795)\n","2022-12-14 20:30:55 | INFO | fairseq_cli.train | quantize: symmetric\n","2022-12-14 20:30:57 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\n","2022-12-14 20:30:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2022-12-14 20:30:57 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.586 GB ; name = A100-SXM4-40GB                          \n","2022-12-14 20:30:57 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n","2022-12-14 20:30:57 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n","2022-12-14 20:30:57 | INFO | fairseq_cli.train | max tokens per GPU = 4400 and max sentences per GPU = 32\n","2022-12-14 20:30:59 | INFO | fairseq.trainer | loaded checkpoint checkpoint_best_SST-2.pt (epoch 13 @ 0 updates)\n","2022-12-14 20:30:59 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16\n","2022-12-14 20:31:00 | INFO | fairseq.trainer | loading train data for epoch 1\n","2022-12-14 20:31:00 | INFO | fairseq.data.data_utils | loaded 67349 examples from: SST-2-bin/input0/train\n","2022-12-14 20:31:00 | INFO | fairseq.data.data_utils | loaded 67349 examples from: SST-2-bin/label/train\n","2022-12-14 20:31:00 | INFO | fairseq.tasks.sentence_prediction | Loaded train with #samples: 67349\n","epoch 001:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 20:31:00 | INFO | fairseq.trainer | begin training epoch 1\n","2022-12-14 20:31:00 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 1\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:02 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:03 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","2022-12-14 20:31:03 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 0 -> 6\n","/content/gdrive/.shortcut-targets-by-id/1RujN8KS4gYHaZ5MKM6blAy_V-kAsq3Rr/I-BERT/fairseq/utils.py:305: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n","  warnings.warn(\n","epoch 001:   1% 16/2105 [00:11<20:41,  1.68it/s]2022-12-14 20:31:12 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 6 -> 7\n","epoch 001:  19% 401/2105 [03:57<16:45,  1.69it/s, loss=0.587, nll_loss=0.044, accuracy=81.7, tp=1080, tn=1535, fp=264, fn=321, false=585, wps=731.1, ups=1.72, wpb=426.2, bsz=32, num_updates=400, lr=9.80893e-07, gnorm=25.957, train_wall=58, wall=240]2022-12-14 20:34:58 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 6 -> 7\n","epoch 001:  25% 534/2105 [05:15<15:17,  1.71it/s, loss=0.538, nll_loss=0.039, accuracy=83.8, tp=1137, tn=1545, fp=253, fn=265, false=518, wps=745.8, ups=1.7, wpb=438.4, bsz=32, num_updates=500, lr=9.76117e-07, gnorm=24.841, train_wall=58, wall=298]2022-12-14 20:36:16 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 7 -> 8\n","epoch 001:  31% 662/2105 [06:30<14:08,  1.70it/s, loss=0.554, nll_loss=0.041, accuracy=82.8, tp=1100, tn=1549, fp=251, fn=300, false=551, wps=731.8, ups=1.71, wpb=427.9, bsz=32, num_updates=600, lr=9.7134e-07, gnorm=24.069, train_wall=58, wall=357]2022-12-14 20:37:31 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 6 -> 7\n","epoch 001:  36% 757/2105 [07:29<13:12,  1.70it/s, loss=0.514, nll_loss=0.038, accuracy=84.9, tp=1207, tn=1499, fp=240, fn=243, false=483, wps=705.6, ups=1.64, wpb=429.9, bsz=31.9, num_updates=700, lr=9.66563e-07, gnorm=24.343, train_wall=61, wall=418]2022-12-14 20:38:29 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 6 -> 7\n","epoch 001: 100% 2104/2105 [20:42<00:00,  1.71it/s, loss=0.359, nll_loss=0.027, accuracy=89.4, tp=1269, tn=1593, fp=170, fn=168, false=338, wps=727.1, ups=1.7, wpb=426.9, bsz=32, num_updates=2100, lr=8.9969e-07, gnorm=22.365, train_wall=58, wall=1243]2022-12-14 20:51:43 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 001 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:   4% 1/28 [00:00<00:15,  1.72it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:   7% 2/28 [00:01<00:13,  1.92it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  11% 3/28 [00:01<00:12,  2.01it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  14% 4/28 [00:02<00:11,  2.05it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  18% 5/28 [00:02<00:11,  2.07it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  21% 6/28 [00:02<00:10,  2.10it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  25% 7/28 [00:03<00:09,  2.11it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  29% 8/28 [00:03<00:09,  2.12it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  32% 9/28 [00:04<00:08,  2.13it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  36% 10/28 [00:04<00:08,  2.14it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  39% 11/28 [00:05<00:07,  2.14it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  43% 12/28 [00:05<00:07,  2.14it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  46% 13/28 [00:06<00:07,  2.13it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  50% 14/28 [00:06<00:06,  2.13it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  54% 15/28 [00:07<00:06,  2.13it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  57% 16/28 [00:07<00:05,  2.12it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  61% 17/28 [00:08<00:05,  2.12it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  64% 18/28 [00:08<00:04,  2.12it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  68% 19/28 [00:09<00:04,  2.07it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  71% 20/28 [00:09<00:03,  2.09it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  75% 21/28 [00:10<00:03,  2.09it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  79% 22/28 [00:10<00:02,  2.10it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  82% 23/28 [00:10<00:02,  2.11it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  86% 24/28 [00:11<00:01,  2.12it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  89% 25/28 [00:11<00:01,  2.14it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  93% 26/28 [00:12<00:00,  2.14it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset:  96% 27/28 [00:12<00:00,  2.15it/s]\u001b[A\n","epoch 001 | valid on 'valid' subset: 100% 28/28 [00:13<00:00,  2.16it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 20:51:57 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 0.301 | nll_loss 0.012 | accuracy 92.5 | tp 393 | tn 414 | fp 30 | fn 35 | false 65 | wps 1654.5 | wpb 778.9 | bsz 31.1 | num_updates 2105\n","2022-12-14 20:51:57 | INFO | fairseq_cli.train | begin save checkpoint\n","2022-12-14 20:52:17 | INFO | fairseq.checkpoint_utils | saved checkpoint outputs/symmetric/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-06/1214-203051_ckpt/checkpoint1.pt (epoch 1 @ 2105 updates, score 92.5) (writing took 19.846516857000097 seconds)\n","2022-12-14 20:52:17 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n","2022-12-14 20:52:17 | INFO | train | epoch 001 | loss 0.48 | nll_loss 0.036 | accuracy 85.5 | tp 24669 | tn 32918 | fp 4651 | fn 5111 | false 9762 | wps 705.9 | ups 1.65 | wpb 427.4 | bsz 32 | num_updates 2105 | lr 8.99451e-07 | gnorm 24.363 | train_wall 1236 | wall 1279\n","epoch 002:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 20:52:17 | INFO | fairseq.trainer | begin training epoch 2\n","epoch 002:  28% 595/2105 [05:54<15:11,  1.66it/s, loss=0.354, nll_loss=0.026, accuracy=90.1, tp=1278, tn=1594, fp=158, fn=159, false=317, wps=740.5, ups=1.71, wpb=433.7, bsz=31.9, num_updates=2700, lr=8.71029e-07, gnorm=22.557, train_wall=58, wall=1634]2022-12-14 20:58:12 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 6 -> 7\n","epoch 002: 100% 2104/2105 [20:56<00:00,  1.55it/s, loss=0.281, nll_loss=0.021, accuracy=92.6, tp=1299, tn=1664, fp=119, fn=118, false=237, wps=690.5, ups=1.65, wpb=418.1, bsz=32, num_updates=4200, lr=7.99379e-07, gnorm=21.926, train_wall=60, wall=2530]2022-12-14 21:13:13 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 002 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:   4% 1/28 [00:00<00:16,  1.66it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:   7% 2/28 [00:01<00:13,  1.88it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  11% 3/28 [00:01<00:12,  1.99it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  14% 4/28 [00:02<00:11,  2.04it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  18% 5/28 [00:02<00:11,  2.05it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  21% 6/28 [00:02<00:10,  2.05it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  25% 7/28 [00:03<00:10,  2.06it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  29% 8/28 [00:03<00:09,  2.06it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  32% 9/28 [00:04<00:09,  2.05it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  36% 10/28 [00:04<00:08,  2.06it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  39% 11/28 [00:05<00:08,  2.07it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  43% 12/28 [00:05<00:07,  2.08it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  46% 13/28 [00:06<00:07,  2.04it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  50% 14/28 [00:06<00:06,  2.04it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  54% 15/28 [00:07<00:06,  2.06it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  57% 16/28 [00:07<00:05,  2.07it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  61% 17/28 [00:08<00:05,  2.09it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  64% 18/28 [00:08<00:04,  2.10it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  68% 19/28 [00:09<00:04,  2.10it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  71% 20/28 [00:09<00:03,  2.11it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  75% 21/28 [00:10<00:03,  2.10it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  79% 22/28 [00:10<00:02,  2.11it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  82% 23/28 [00:11<00:02,  2.11it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  86% 24/28 [00:11<00:01,  2.12it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  89% 25/28 [00:12<00:01,  2.13it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  93% 26/28 [00:12<00:00,  2.12it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset:  96% 27/28 [00:13<00:00,  2.12it/s]\u001b[A\n","epoch 002 | valid on 'valid' subset: 100% 28/28 [00:13<00:00,  2.14it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 21:13:27 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 0.32 | nll_loss 0.013 | accuracy 92.4 | tp 390 | tn 416 | fp 28 | fn 38 | false 66 | wps 1628.9 | wpb 778.9 | bsz 31.1 | num_updates 4210 | best_accuracy 92.5\n","2022-12-14 21:13:27 | INFO | fairseq_cli.train | begin save checkpoint\n","2022-12-14 21:13:42 | INFO | fairseq.checkpoint_utils | saved checkpoint outputs/symmetric/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-06/1214-203051_ckpt/checkpoint2.pt (epoch 2 @ 4210 updates, score 92.4) (writing took 14.715526234998833 seconds)\n","2022-12-14 21:13:42 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n","2022-12-14 21:13:42 | INFO | train | epoch 002 | loss 0.319 | nll_loss 0.024 | accuracy 91.1 | tp 26793 | tn 34565 | fp 3004 | fn 2987 | false 5991 | wps 700.2 | ups 1.64 | wpb 427.4 | bsz 32 | num_updates 4210 | lr 7.98901e-07 | gnorm 21.927 | train_wall 1250 | wall 2564\n","epoch 003:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 21:13:42 | INFO | fairseq.trainer | begin training epoch 3\n","epoch 003:  24% 509/2105 [05:02<15:34,  1.71it/s, loss=0.281, nll_loss=0.021, accuracy=91.9, tp=1263, tn=1678, fp=125, fn=134, false=259, wps=718.1, ups=1.7, wpb=422.2, bsz=32, num_updates=4700, lr=7.75496e-07, gnorm=21.312, train_wall=58, wall=2855]2022-12-14 21:18:44 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 6 -> 7\n","epoch 003:  98% 2062/2105 [20:14<00:25,  1.72it/s, loss=0.276, nll_loss=0.02, accuracy=92.6, tp=1313, tn=1651, fp=120, fn=116, false=236, wps=736.7, ups=1.7, wpb=432.6, bsz=32, num_updates=6200, lr=7.03845e-07, gnorm=19.826, train_wall=58, wall=3737]2022-12-14 21:33:57 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 6 -> 7\n","epoch 003: 100% 2104/2105 [20:39<00:00,  1.72it/s, loss=0.274, nll_loss=0.021, accuracy=92.4, tp=1285, tn=1672, fp=116, fn=127, false=243, wps=729.8, ups=1.71, wpb=427.8, bsz=32, num_updates=6300, lr=6.99069e-07, gnorm=19.122, train_wall=58, wall=3796]2022-12-14 21:34:22 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 003 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:   4% 1/28 [00:00<00:16,  1.67it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:   7% 2/28 [00:01<00:13,  1.92it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  11% 3/28 [00:01<00:12,  1.99it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  14% 4/28 [00:02<00:11,  2.03it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  18% 5/28 [00:02<00:11,  2.06it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  21% 6/28 [00:02<00:10,  2.09it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  25% 7/28 [00:03<00:09,  2.11it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  29% 8/28 [00:03<00:09,  2.13it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  32% 9/28 [00:04<00:08,  2.13it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  36% 10/28 [00:04<00:08,  2.13it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  39% 11/28 [00:05<00:07,  2.13it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  43% 12/28 [00:05<00:07,  2.13it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  46% 13/28 [00:06<00:07,  2.11it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  50% 14/28 [00:06<00:06,  2.11it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  54% 15/28 [00:07<00:06,  2.12it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  57% 16/28 [00:07<00:05,  2.11it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  61% 17/28 [00:08<00:05,  2.12it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  64% 18/28 [00:08<00:04,  2.12it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  68% 19/28 [00:09<00:04,  2.12it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  71% 20/28 [00:09<00:03,  2.12it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  75% 21/28 [00:10<00:03,  2.12it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  79% 22/28 [00:10<00:02,  2.09it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  82% 23/28 [00:10<00:02,  2.10it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  86% 24/28 [00:11<00:01,  2.12it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  89% 25/28 [00:11<00:01,  2.14it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  93% 26/28 [00:12<00:00,  2.14it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset:  96% 27/28 [00:12<00:00,  2.14it/s]\u001b[A\n","epoch 003 | valid on 'valid' subset: 100% 28/28 [00:13<00:00,  2.16it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 21:34:35 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 0.318 | nll_loss 0.013 | accuracy 91.9 | tp 387 | tn 414 | fp 30 | fn 41 | false 71 | wps 1655.4 | wpb 778.9 | bsz 31.1 | num_updates 6315 | best_accuracy 92.5\n","2022-12-14 21:34:35 | INFO | fairseq_cli.train | begin save checkpoint\n","2022-12-14 21:34:48 | INFO | fairseq.checkpoint_utils | saved checkpoint outputs/symmetric/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-06/1214-203051_ckpt/checkpoint3.pt (epoch 3 @ 6315 updates, score 91.9) (writing took 12.804171154999494 seconds)\n","2022-12-14 21:34:48 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n","2022-12-14 21:34:48 | INFO | train | epoch 003 | loss 0.276 | nll_loss 0.021 | accuracy 92.2 | tp 27161 | tn 34963 | fp 2606 | fn 2619 | false 5225 | wps 710.7 | ups 1.66 | wpb 427.4 | bsz 32 | num_updates 6315 | lr 6.98352e-07 | gnorm 20.774 | train_wall 1233 | wall 3830\n","epoch 004:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 21:34:48 | INFO | fairseq.trainer | begin training epoch 4\n","epoch 004:  42% 888/2105 [08:43<11:54,  1.70it/s, loss=0.252, nll_loss=0.019, accuracy=92.8, tp=1281, tn=1690, fp=108, fn=121, false=229, wps=725.8, ups=1.71, wpb=423.7, bsz=32, num_updates=7200, lr=6.56078e-07, gnorm=19.969, train_wall=58, wall=4352]2022-12-14 21:43:31 | INFO | fairseq.quantization.utils.quant_modules | Dynamic shift adjustment: 7 -> 8\n","epoch 004: 100% 2104/2105 [20:34<00:00,  1.71it/s, loss=0.24, nll_loss=0.018, accuracy=93.3, tp=1291, tn=1695, fp=112, fn=102, false=214, wps=720.3, ups=1.71, wpb=421.6, bsz=32, num_updates=8400, lr=5.98758e-07, gnorm=18.9, train_wall=58, wall=5054]2022-12-14 21:55:23 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n","\n","epoch 004 | valid on 'valid' subset:   0% 0/28 [00:00<?, ?it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:   4% 1/28 [00:00<00:16,  1.68it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:   7% 2/28 [00:01<00:13,  1.91it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  11% 3/28 [00:01<00:12,  2.00it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  14% 4/28 [00:02<00:11,  2.04it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  18% 5/28 [00:02<00:11,  2.01it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  21% 6/28 [00:02<00:10,  2.05it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  25% 7/28 [00:03<00:10,  2.09it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  29% 8/28 [00:03<00:09,  2.08it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  32% 9/28 [00:04<00:09,  2.10it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  36% 10/28 [00:04<00:08,  2.11it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  39% 11/28 [00:05<00:08,  2.12it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  43% 12/28 [00:05<00:07,  2.13it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  46% 13/28 [00:06<00:07,  2.13it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  50% 14/28 [00:06<00:06,  2.13it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  54% 15/28 [00:07<00:06,  2.14it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  57% 16/28 [00:07<00:05,  2.13it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  61% 17/28 [00:08<00:05,  2.13it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  64% 18/28 [00:08<00:04,  2.13it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  68% 19/28 [00:09<00:04,  2.12it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  71% 20/28 [00:09<00:03,  2.13it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  75% 21/28 [00:10<00:03,  2.10it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  79% 22/28 [00:10<00:02,  2.11it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  82% 23/28 [00:10<00:02,  2.11it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  86% 24/28 [00:11<00:01,  2.12it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  89% 25/28 [00:11<00:01,  2.13it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  93% 26/28 [00:12<00:00,  2.14it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset:  96% 27/28 [00:12<00:00,  2.14it/s]\u001b[A\n","epoch 004 | valid on 'valid' subset: 100% 28/28 [00:13<00:00,  2.16it/s]\u001b[A\n","                                                                        \u001b[A2022-12-14 21:55:36 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 0.325 | nll_loss 0.013 | accuracy 93.2 | tp 393 | tn 420 | fp 24 | fn 35 | false 59 | wps 1652 | wpb 778.9 | bsz 31.1 | num_updates 8420 | best_accuracy 93.2\n","2022-12-14 21:55:36 | INFO | fairseq_cli.train | begin save checkpoint\n","2022-12-14 21:55:56 | INFO | fairseq.checkpoint_utils | saved checkpoint outputs/symmetric/SST-2-base/wd0.1_ad0.1_d0.1_lr1e-06/1214-203051_ckpt/checkpoint4.pt (epoch 4 @ 8420 updates, score 93.2) (writing took 20.513047677999566 seconds)\n","2022-12-14 21:55:56 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n","2022-12-14 21:55:56 | INFO | train | epoch 004 | loss 0.256 | nll_loss 0.019 | accuracy 92.9 | tp 27433 | tn 35150 | fp 2419 | fn 2347 | false 4766 | wps 709.1 | ups 1.66 | wpb 427.4 | bsz 32 | num_updates 8420 | lr 5.97803e-07 | gnorm 19.237 | train_wall 1228 | wall 5099\n","epoch 005:   0% 0/2105 [00:00<?, ?it/s]2022-12-14 21:55:56 | INFO | fairseq.trainer | begin training epoch 5\n","epoch 005:  72% 1513/2105 [14:46<05:48,  1.70it/s, loss=0.226, nll_loss=0.017, accuracy=93.9, tp=1279, tn=1727, fp=102, fn=92, false=194, wps=721.1, ups=1.71, wpb=421.3, bsz=32, num_updates=9900, lr=5.27108e-07, gnorm=19.121, train_wall=58, wall=5966]"]}],"source":["!CUDA_VISIBLE_DEVICES=0 python run.py --arch roberta_base --task SST-2 --restore-file checkpoint_best_SST-2.pt --lr 1e-6 "]},{"cell_type":"code","source":["!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"me6jpEpLLgWG","outputId":"f73f922f-9f46-40b3-a3b0-af1eae3b6b15"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/coms6998_project/I-BERT\n"]}]},{"cell_type":"code","source":["!which python3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVG6f1slN79X","outputId":"fbf93902-f11b-4f04-8543-7d780e3f7abb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/bin/python3\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QMHCJH94gpOc"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}